<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8" />
    <title>Venesa Voice</title>
    <style>
        @import url("https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap");

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        :root {
            --font: "Segoe UI Variable", "Inter", -apple-system, system-ui, sans-serif;
            --primary: #c979ee;
            --accent1: #74bcd6;
            --accent2: #ef788c;
            --background: #e7e7fb;
            --highlight: #eb7fc6;
            --text-primary: rgba(30, 30, 40, 0.9);
        }

        html,
        body {
            height: 100%;
            width: 100%;
            overflow: hidden;
            margin: 0;
            padding: 0;
            background: transparent;
            font-family: var(--font);
            color: var(--text-primary);
        }

        /* Main container - full screen workspace */
        .voice-workspace {
            width: 100%;
            height: 100%;
            display: flex;
            flex-direction: column;
            position: relative;
            background: linear-gradient(135deg,
                    rgba(231, 231, 251, 0.98) 0%,
                    rgba(201, 121, 238, 0.15) 50%,
                    rgba(116, 188, 214, 0.15) 100%);
            backdrop-filter: blur(10px);
        }

        /* Captured image background (full screen) */
        .capture-preview {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: contain;
            opacity: 0;
            transition: opacity 0.5s ease;
            z-index: 0;
            pointer-events: none;
        }

        .capture-preview.visible {
            opacity: 0.15;
            /* Subtle background context */
        }

        /* Transcript display */
        .transcript-area {
            position: absolute;
            bottom: 220px;
            /* Above blob */
            left: 50%;
            transform: translateX(-50%);
            width: 80%;
            text-align: center;
            font-size: 24px;
            font-weight: 500;
            color: var(--text-primary);
            text-shadow: 0 2px 10px rgba(255, 255, 255, 0.8);
            opacity: 0;
            transition: opacity 0.3s ease;
            z-index: 10;
        }

        .transcript-area.visible {
            opacity: 1;
        }

        .transcript-area .interim {
            color: var(--text-primary);
            opacity: 0.6;
        }

        /* Response display */
        .response-area {
            position: absolute;
            top: 40%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 70%;
            max-height: 50%;
            overflow-y: auto;
            text-align: center;
            font-size: 18px;
            line-height: 1.6;
            color: var(--text-primary);
            background: rgba(255, 255, 255, 0.6);
            padding: 30px;
            border-radius: 20px;
            backdrop-filter: blur(15px);
            box-shadow: 0 10px 40px rgba(201, 121, 238, 0.2);
            opacity: 0;
            transition: all 0.4s cubic-bezier(0.16, 1, 0.3, 1);
            z-index: 10;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }

        .response-area.visible {
            opacity: 1;
            transform: translate(-50%, -50%) scale(1);
        }

        /* Bottom voice indicator container */
        .voice-indicator {
            position: absolute;
            bottom: 40px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 12px;
            z-index: 20;
        }

        /* === BLOB ANIMATION (LARGER & BOUNCY) === */
        .ai {
            --s: 140px;
            /* Larger */
            --p: calc(var(--s) / 4);
            width: var(--s);
            aspect-ratio: 1;
            padding: var(--p);
            display: grid;
            place-items: center;
            position: relative;
            cursor: pointer;
            transition: transform 0.2s cubic-bezier(0.34, 1.56, 0.64, 1);
        }

        /* Giggle animation class */
        .ai.giggle {
            animation: giggle 0.4s ease-in-out;
        }

        @keyframes giggle {

            0%,
            100% {
                transform: scale(1);
            }

            25% {
                transform: scale(1.1) rotate(-3deg);
            }

            50% {
                transform: scale(0.95) rotate(3deg);
            }

            75% {
                transform: scale(1.05) rotate(-2deg);
            }
        }

        .ai::before,
        .ai::after {
            content: "";
            position: absolute;
            top: 50%;
            left: 50%;
            width: 60%;
            height: 60%;
            border-radius: 50%;
            border: 2px solid white;
            box-shadow: 0 0 20px var(--primary);
            filter: blur(4px);
            transform: translate(-50%, -50%);
            opacity: 0;
        }

        .ai.listening::before {
            animation: wave 2s linear infinite;
        }

        .ai.listening::after {
            animation: wave 2s linear infinite 0.6s;
        }

        @keyframes wave {
            0% {
                transform: translate(-50%, -50%) scale(0.8);
                opacity: 0.6;
            }

            100% {
                transform: translate(-50%, -50%) scale(2);
                opacity: 0;
            }
        }

        /* Core animations */
        @keyframes ai1 {
            0% {
                transform: rotate(0deg);
            }

            100% {
                transform: rotate(360deg);
            }
        }

        @keyframes ai2 {
            0% {
                transform: rotate(360deg);
            }

            100% {
                transform: rotate(0deg);
            }
        }

        .container {
            width: 100%;
            height: 100%;
            border-radius: 50%;
            position: relative;
            animation: breath 4s ease-in-out infinite alternate;
        }

        @keyframes breath {
            from {
                transform: scale(0.95);
            }

            to {
                transform: scale(1.05);
            }
        }

        .glass {
            position: absolute;
            inset: -10px;
            border-radius: 50%;
            backdrop-filter: blur(12px);
            background: radial-gradient(circle at 30% 30%, rgba(255, 255, 255, 0.8), rgba(255, 255, 255, 0.2) 60%, transparent 80%);
            box-shadow: 0 10px 30px rgba(201, 121, 238, 0.4), inset 0 0 20px rgba(255, 255, 255, 0.5);
            z-index: 2;
        }

        /* Inner colorful blobs */
        .blobs {
            position: absolute;
            inset: 10px;
            border-radius: 50%;
            overflow: hidden;
            z-index: 1;
            filter: blur(8px);
            background: white;
        }

        .blob {
            position: absolute;
            border-radius: 50%;
            opacity: 0.8;
        }

        .blob:nth-child(1) {
            width: 80%;
            height: 80%;
            background: var(--primary);
            top: -10%;
            left: -10%;
            animation: move1 6s infinite alternate;
        }

        .blob:nth-child(2) {
            width: 70%;
            height: 70%;
            background: var(--accent1);
            bottom: -10%;
            right: -10%;
            animation: move2 7s infinite alternate;
        }

        .blob:nth-child(3) {
            width: 60%;
            height: 60%;
            background: var(--accent2);
            bottom: 10%;
            left: 30%;
            animation: move3 5s infinite alternate;
        }

        @keyframes move1 {
            from {
                transform: translate(0, 0);
            }

            to {
                transform: translate(20px, 20px);
            }
        }

        @keyframes move2 {
            from {
                transform: translate(0, 0);
            }

            to {
                transform: translate(-20px, -10px);
            }
        }

        @keyframes move3 {
            from {
                transform: translate(0, 0);
            }

            to {
                transform: translate(10px, -20px);
            }
        }

        /* Status text */
        .status-text {
            font-size: 13px;
            font-weight: 500;
            color: var(--text-primary);
            opacity: 0.8;
            letter-spacing: 0.5px;
            background: rgba(255, 255, 255, 0.5);
            padding: 4px 12px;
            border-radius: 20px;
        }
    </style>
</head>

<body>
    <div class="voice-workspace">
        <!-- Full Context Background -->
        <img class="capture-preview" id="capturePreview" src="" />

        <!-- Transcript -->
        <div class="transcript-area" id="transcriptArea">
            <span class="final" id="finalTranscript"></span>
            <span class="interim" id="interimTranscript"></span>
        </div>

        <!-- AI Response -->
        <div class="response-area" id="responseArea"></div>

        <!-- Voice Indicator -->
        <div class="voice-indicator">
            <div class="ai" id="aiBlob">
                <div class="glass"></div>
                <div class="blobs">
                    <div class="blob"></div>
                    <div class="blob"></div>
                    <div class="blob"></div>
                </div>
            </div>
            <span class="status-text" id="statusText">Listening...</span>
        </div>
    </div>

    <script>
        const aiBlob = document.getElementById('aiBlob');
        const statusText = document.getElementById('statusText');
        const transcriptArea = document.getElementById('transcriptArea');
        const finalTranscript = document.getElementById('finalTranscript');
        const interimTranscript = document.getElementById('interimTranscript');
        const responseArea = document.getElementById('responseArea');
        const capturePreview = document.getElementById('capturePreview');

        let recognition = null;
        let isListening = false;
        let capturedImageData = null;
        let autoRestartTimer = null;

        // States
        function setState(state) {
            aiBlob.classList.remove('listening', 'thinking', 'responding');

            switch (state) {
                case 'listening':
                    aiBlob.classList.add('listening');
                    statusText.textContent = 'Listening...';
                    transcriptArea.classList.add('visible');
                    responseArea.classList.remove('visible');
                    break;
                case 'thinking':
                    aiBlob.classList.add('thinking');
                    statusText.textContent = 'Thinking...';
                    // Giggle effect while thinking
                    giggle();
                    break;
                case 'responding':
                    aiBlob.classList.add('responding');
                    statusText.textContent = 'Speaking...';
                    transcriptArea.classList.remove('visible');
                    responseArea.classList.add('visible');
                    break;
            }
        }

        function giggle() {
            aiBlob.classList.remove('giggle');
            void aiBlob.offsetWidth; // trigger reflow
            aiBlob.classList.add('giggle');
        }

        function initSpeechRecognition() {
            if ('webkitSpeechRecognition' in window) {
                recognition = new webkitSpeechRecognition();
                recognition.continuous = true;
                recognition.interimResults = true;
                recognition.lang = 'en-US';

                recognition.onstart = () => {
                    isListening = true;
                    setState('listening');
                };

                recognition.onresult = (event) => {
                    let interim = '';
                    let final = '';

                    for (let i = event.resultIndex; i < event.results.length; i++) {
                        if (event.results[i].isFinal) {
                            final += event.results[i][0].transcript;
                        } else {
                            interim += event.results[i][0].transcript;
                        }
                    }

                    // "Giggle" on voice input
                    if (interim.length > 0 || final.length > 0) {
                        if (Math.random() > 0.7) giggle();
                    }

                    if (final) {
                        finalTranscript.textContent = final;
                        processQuery(final.trim());
                    }
                    interimTranscript.textContent = interim;
                };

                recognition.onend = () => {
                    // Force restart if supposed to be listening
                    if (isListening) {
                        clearTimeout(autoRestartTimer);
                        autoRestartTimer = setTimeout(() => {
                            try { recognition.start(); } catch (e) { }
                        }, 100);
                    }
                };

                recognition.onerror = () => {
                    clearTimeout(autoRestartTimer);
                    autoRestartTimer = setTimeout(() => {
                        try { recognition.start(); } catch (e) { }
                    }, 500);
                };
            }
        }

        function startListening() {
            if (recognition && !isListening) {
                try { recognition.start(); } catch (e) { }
            }
        }

        function processQuery(query) {
            if (!query) return;
            setState('thinking');

            // Auto-capture screen for context
            window.voiceApi.send('capture-screen');

            // Wait briefly for capture to be ready (handled by main -> screen-captured -> send query)
            // Actually, logic is: Request Capture -> Get Capture -> Send Query
            // But main process sends 'screen-captured' back to here.
            // We need to store the query and wait for capture.

            window.pendingQuery = query;
        }

        // IPC Handlers
        window.voiceApi.receive('screen-captured', (imageData) => {
            capturedImageData = imageData;
            capturePreview.src = imageData;
            capturePreview.classList.add('visible');

            // Now send query with image
            if (window.pendingQuery) {
                window.voiceApi.send('voice-query', {
                    query: window.pendingQuery,
                    image: imageData
                });
                window.pendingQuery = null;
            }
        });

        window.voiceApi.receive('voice-response', (text) => {
            setState('responding');
            responseArea.textContent = text;

            if ('speechSynthesis' in window) {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.onend = () => {
                    setState('listening');
                    finalTranscript.textContent = '';
                    interimTranscript.textContent = '';
                    // Hide context after done
                    capturePreview.classList.remove('visible');
                };
                speechSynthesis.speak(utterance);
            } else {
                setTimeout(() => {
                    setState('listening');
                    capturePreview.classList.remove('visible');
                }, 4000);
            }
        });

        window.voiceApi.receive('start-listening', () => {
            startListening();
        });

        // Init
        initSpeechRecognition();
        window.addEventListener('load', () => {
            window.voiceApi.send('voice-window-ready');
        });
    </script>
</body>

</html>